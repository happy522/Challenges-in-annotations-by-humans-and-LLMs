# This is the prompt initially created by Aenne based on the LR. 
#Used the last part of Kushi's prompt examples

"""
You are a research assistant.

Annotate the text according to the Appraisal Theory. Annotate each text with one of the following categories: affect, judgement, appraisal, or ambiguous.

Letâ€™s think step-by-step.

## Output Format
Return a JSON object. For a single input text, output an object with the following fields:
- "label": one of ("affect", "judgement", "appraisal", "ambiguous")
- "reasoning": a brief explanation of why this label was chosen.

For multiple input texts, output a JSON array where each entry is an object as specified above, corresponding to the input texts in order.

Example (single text):
{
  "label": "judgement",
  "reasoning": "The text expresses an evaluation of someone's behavior according to social norms."
}

Example (multiple texts):
[
  {"label": "affect", "reasoning": "The sentence communicates an emotional state."},
  {"label": "ambiguous", "reasoning": "It is unclear whether this represents an appraisal, affect, or judgement."}
]

Important constraints:
- Base your decision ONLY on the given texts and the definitions above.
- Do NOT invent extra information or background that is not in the context.
- If two or more categories are clearly present and one is clearly dominant, choose the dominant one (not ambiguous).
- If you genuinely cannot decide which category is primary, use "ambiguous" and mark the candidates.

Output format:
Return ONLY a single valid JSON object (no extra text).

Use exactly these fields:
- "label": one of "affect", "judgment", "appreciation", "ambiguous"
- "affect": 0 or 1  (1 if affect is present/relevant)
- "judgment": 0 or 1  (1 if judgment is present/relevant)
- "appreciation": 0 or 1  (1 if appreciation is present/relevant)
- "probability": a float between 0.0 and 1.0 for the chosen main label in "label"
- "top_spans": a list (max 3 items) of short quotes from the TARGET that support your decision
- "explanation": a short explanation (max 60 words) of why you chose this label and flags,
                 explicitly linking to the definitions above.

Context:

PREVIOUS:
\"\"\"{prev_text}\"\"\"

TARGET:
\"\"\"{target_text}\"\"\"

NEXT:
\"\"\"{next_text}\"\"\"
"""


This were the results:




=== Multiclass (Affect / Judgment / Appreciation) ===
Accuracy:        0.500
Macro Precision: 0.667
Macro Recall:    0.458
Macro F1:        0.515
Micro Precision: 1.000
Micro Recall:    0.500
Micro F1:        0.667

Classification report (multiclass):
              precision    recall  f1-score   support

      affect      1.000     1.000     1.000         4
    judgment      0.000     0.000     0.000         2
appreciation      1.000     0.375     0.545         8

   micro avg      1.000     0.500     0.667        14
   macro avg      0.667     0.458     0.515        14
weighted avg      0.857     0.500     0.597        14


Confusion matrix (multiclass):
[[4 0 0]
 [0 0 0]
 [0 0 3]]
