{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ART:\n",
        "\n",
        "### Art5_Camila_Yael_Dip_Perfumo.xlsx -Cohen's Kappa: -0.3084112149532712\n",
        "\n",
        "Skipping Evaluative: Only one unique value ([1]) after filtering for Evaluative=1.\n",
        "\n",
        "Skipping Ambiguous: Only one unique value ([0]) after filtering for Evaluative=1.\n",
        "\n",
        "Krippendorff's Alpha for Affect: -0.100\n",
        "\n",
        "Krippendorff's Alpha for Judgement: 0.000\n",
        "\n",
        "Krippendorff's Alpha for Appreciation: -0.222\n",
        "\n",
        "####(There is a problem in data, when sentece evaulative = 0 but still there are values in other columns) - Hence we are rejecting this.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Art5_Oliwia_Wierzba.xlsx - Cohen's Kappa: -0.012658227848101111\n",
        "\n",
        "Skipping Evaluative: Only one unique value ([1]) after filtering for Evaluative=1.\n",
        "\n",
        "Krippendorff's Alpha for Affect: -0.500\n",
        "\n",
        "Krippendorff's Alpha for Judgement: 0.259\n",
        "\n",
        "Krippendorff's Alpha for Appreciation: 0.250\n",
        "\n",
        "Krippendorff's Alpha for Ambiguous: -0.235\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "### Art5_Paulina_Piotrowska.xlsx - Cohen's Kappa: 0.140625\n",
        "\n",
        "Skipping Evaluative: Only one unique value ([1]) after filtering for Evaluative=1.\n",
        "\n",
        "Skipping Judgement: Only one unique value ([0]) after filtering for Evaluative=1.\n",
        "\n",
        "Skipping Ambiguous: Only one unique value ([0]) after filtering for Evaluative=1.\n",
        "\n",
        "Krippendorff's Alpha for Affect: -0.222\n",
        "\n",
        "Krippendorff's Alpha for Appreciation: -0.222"
      ],
      "metadata": {
        "id": "bPOR8QNbWvkw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tech\n",
        "\n",
        "### Tech10_Josefine_Baer.xls - Cohen's Kappa: 0.3137254901960784\n",
        "\n",
        "Skipping Evaluative: Only one unique value ([1]) after filtering for Evaluative=1.\n",
        "\n",
        "Skipping Judgement: Only one unique value ([0]) after filtering for Evaluative=1.\n",
        "\n",
        "Krippendorff's Alpha for Affect: -0.300\n",
        "\n",
        "Krippendorff's Alpha for Appreciation: -0.182\n",
        "\n",
        "Krippendorff's Alpha for Ambiguous: 0.000\n",
        "\n",
        "---\n",
        "### Tech10_Josephine_Schmitter.xlsx - Cohen's Kappa: 0.13043478260869557\n",
        "\n",
        "Skipping Evaluative: Only one unique value ([1]) after filtering for Evaluative=1.\n",
        "\n",
        "Krippendorff's Alpha for Affect: 0.215\n",
        "\n",
        "Krippendorff's Alpha for Judgement: -0.104\n",
        "\n",
        "Krippendorff's Alpha for Appreciation: -0.049\n",
        "\n",
        "Krippendorff's Alpha for Ambiguous: 0.000\n",
        "\n",
        "(Removing this - low cohen's kappa)\n",
        "---\n",
        "### Tech10_Sean-Pascal_Kuttner.xlsx - Cohen's Kappa: 0.4897959183673469\n",
        "\n",
        "Skipping Evaluative: Only one unique value ([1]) after filtering for Evaluative=1.\n",
        "\n",
        "Krippendorff's Alpha for Affect: -0.133\n",
        "\n",
        "Krippendorff's Alpha for Judgement: -0.133\n",
        "\n",
        "Krippendorff's Alpha for Appreciation: 0.393\n",
        "\n",
        "Krippendorff's Alpha for Ambiguous: -0.062"
      ],
      "metadata": {
        "id": "ANdLai5BHEvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip output.zip -d /content/output"
      ],
      "metadata": {
        "id": "Sm6n67H8XHW8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e8b947c-417e-4fed-d423-532236952f35"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  output.zip\n",
            "   creating: /content/output/output/\n",
            "  inflating: /content/output/output/Art_Oliwia_Wierzba_merged.xlsx  \n",
            "  inflating: /content/output/output/Art_Paulina_Piotrowska_merged.xlsx  \n",
            "  inflating: /content/output/output/Bus_Leonie_Wessa_merged.xlsx  \n",
            "  inflating: /content/output/output/Bus_Oliwia_Wierzba_merged.xlsx  \n",
            "  inflating: /content/output/output/Edu_Elina_Arendt_merged.xlsx  \n",
            "  inflating: /content/output/output/Edu_Macie_Kilandi_merged.xlsx  \n",
            "  inflating: /content/output/output/Ent_Laura_Bach_merged.xlsx  \n",
            "  inflating: /content/output/output/Ent_Sofie_Wüller_merged.xlsx  \n",
            "  inflating: /content/output/output/His_Marta_MartinezSerrano_merged.xlsx  \n",
            "  inflating: /content/output/output/His_Yolanda_Ortega_merged.xlsx  \n",
            "  inflating: /content/output/output/Med_Maria_SuarezPena_merged.xlsx  \n",
            "  inflating: /content/output/output/Med_Marta_Murcia_Tárraga_merged.xlsx  \n",
            "  inflating: /content/output/output/Phi_Sema_Erkus_merged.xlsx  \n",
            "  inflating: /content/output/output/Phi_Vanessa_Giesbrecht_merged.xlsx  \n",
            "  inflating: /content/output/output/Pol_Chrysoula_Choutouris_merged.xlsx  \n",
            "  inflating: /content/output/output/Pol_Ela_Erkasap_merged.xlsx  \n",
            "  inflating: /content/output/output/Psy_Artem_Kilp_merged.xlsx  \n",
            "  inflating: /content/output/output/Psy_Fabian_Maurice_Heinze_merged.xlsx  \n",
            "  inflating: /content/output/output/Sci_Chiara_Luisa_Büschel_merged.xlsx  \n",
            "  inflating: /content/output/output/Sci_Martin_Junge_merged.xlsx  \n",
            "  inflating: /content/output/output/Tech_Josefine_Baer.xls  \n",
            "  inflating: /content/output/output/Tech_Sean-Pascal_Kuttner_merged.xlsx  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r output.zip output"
      ],
      "metadata": {
        "id": "_QpZXMidHD7w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8233d753-8b6c-4fa0-957e-cf587216e35b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: output/ (stored 0%)\n",
            "  adding: output/Edu_Macie_Kilandi_merged.xlsx (deflated 7%)\n",
            "  adding: output/Pol_2_Chrysoula_Choutouris_merged.xlsx (deflated 7%)\n",
            "  adding: output/Phi_Vanessa_Giesbrecht_merged.xlsx (deflated 9%)\n",
            "  adding: output/Art_Paulina_Piotrowska_merged.xlsx (deflated 7%)\n",
            "  adding: output/Sci_ChiaraLuisaBüschel_merged.xlsx (deflated 8%)\n",
            "  adding: output/Bus_Leonie_Wessa_merged.xlsx (deflated 7%)\n",
            "  adding: output/Med_Maria_SuarezPena_merged.xlsx (deflated 8%)\n",
            "  adding: output/Edu_Elina_Arendt_merged.xlsx (deflated 7%)\n",
            "  adding: output/Phi_Sema_Erkus_merged.xlsx (deflated 8%)\n",
            "  adding: output/Sci_Chiara_Luisa_Büschel_merged.xlsx (deflated 9%)\n",
            "  adding: output/Ent_Sofie_Wüller_merged.xlsx (deflated 9%)\n",
            "  adding: output/Pol_Chrysoula_Choutouris_merged.xlsx (deflated 7%)\n",
            "  adding: output/Med_Maria_SuarezPeña_merged.xlsx (deflated 7%)\n",
            "  adding: output/His_Marta_MartínezSerrano_merged.xlsx (deflated 8%)\n",
            "  adding: output/Bus_Oliwia_Wierzba_merged.xlsx (deflated 6%)\n",
            "  adding: output/Psy_Fabian-M_Heinze_merged.xlsx (deflated 8%)\n",
            "  adding: output/Med_Marta_Murcia_Tárraga_merged.xlsx (deflated 8%)\n",
            "  adding: output/His_Yolanda_Ortega_merged.xlsx (deflated 7%)\n",
            "  adding: output/Sci_Martin_Junge_merged.xlsx (deflated 9%)\n",
            "  adding: output/Art_Oliwia_Wierzba_merged.xlsx (deflated 7%)\n",
            "  adding: output/Ent_Laura_Bach_merged.xlsx (deflated 10%)\n",
            "  adding: output/Psy_Fabian_Maurice_Heinze_merged.xlsx (deflated 8%)\n",
            "  adding: output/Tech_Sean-Pascal_Kuttner_merged.xlsx (deflated 7%)\n",
            "  adding: output/Pol_Ela_Erkasap_merged.xlsx (deflated 7%)\n",
            "  adding: output/His_Marta_MartinezSerrano_merged.xlsx (deflated 7%)\n",
            "  adding: output/Psy_Artem_Kilp_merged.xlsx (deflated 8%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install krippendorff"
      ],
      "metadata": {
        "id": "I0MbPtFzMT-Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a21f4701-5893-4fe2-acfc-624973dd5b09"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting krippendorff\n",
            "  Downloading krippendorff-0.8.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.21 in /usr/local/lib/python3.12/dist-packages (from krippendorff) (2.0.2)\n",
            "Downloading krippendorff-0.8.2-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: krippendorff\n",
            "Successfully installed krippendorff-0.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SDISSYirx4mS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "import krippendorff\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "\n",
        "def extract_disc_author(filename):\n",
        "    \"\"\"\n",
        "    From: 'Edu_Macie_Kilandi_merged.xlsx'\n",
        "    → discipline='Edu'\n",
        "    → author='Macie_Kilandi'\n",
        "    (removes 'merged' and file extension)\n",
        "    \"\"\"\n",
        "    base = os.path.splitext(filename)[0]         # remove .xlsx\n",
        "    base = base.replace(\"_merged\", \"\")           # remove merged\n",
        "    parts = base.split(\"_\")\n",
        "\n",
        "    discipline = parts[0]                        # first token\n",
        "    author = \"_\".join(parts[1:])                 # everything after\n",
        "\n",
        "    return discipline, author\n",
        "\n",
        "\n",
        "# ---- Function to compute Krippendorff's Alpha ---- #\n",
        "\n",
        "def calculate_krippendorffs_alpha(df_list, columns):\n",
        "    alphas = {}\n",
        "    for col in columns:\n",
        "        data = []\n",
        "        for df in df_list:\n",
        "            col_data = df[col].replace(-1, np.nan).to_numpy()\n",
        "            data.append(col_data)\n",
        "        data = np.array(data)\n",
        "\n",
        "        # Skip if only one unique value\n",
        "        unique_values = np.unique(data[~np.isnan(data)])\n",
        "        if len(unique_values) <= 1:\n",
        "            alphas[col] = np.nan\n",
        "            continue\n",
        "\n",
        "        alphas[col] = krippendorff.alpha(\n",
        "            reliability_data=data,\n",
        "            level_of_measurement=\"nominal\"\n",
        "        )\n",
        "    return alphas\n",
        "\n",
        "\n",
        "# ---- MAIN LOOP: iterate through files ---- #\n",
        "\n",
        "results = []\n",
        "\n",
        "gold_file = \"/content/Gold_standard_Mirela.xlsx\"\n",
        "df_gold = pd.read_excel(gold_file)\n",
        "\n",
        "# Normalize gold file\n",
        "df_gold = df_gold.fillna(0)\n",
        "for col in ['Evaluative','Affect','Judgement','Appreciation','Ambiguous']:\n",
        "    df_gold[col] = df_gold[col].astype(int)\n",
        "\n",
        "# Path where student files live\n",
        "student_files = glob.glob(\"/content/output/output/*.xlsx\")\n",
        "print(student_files)\n",
        "for file in student_files:\n",
        "\n",
        "    df2 = pd.read_excel(file)\n",
        "\n",
        "    # Clean student file\n",
        "    # Identify any column whose name equals 'uncertain' ignoring case\n",
        "    uncertain_cols = [c for c in df2.columns if c.lower() == 'uncertain']\n",
        "\n",
        "    # Remove rows where uncertain == 1\n",
        "    for col in uncertain_cols:\n",
        "        df2 = df2[df2[col] != 1]\n",
        "\n",
        "    df2 = df2.drop(['uncertain','Notes'], axis=1, errors='ignore').fillna(0)\n",
        "    for col in ['Evaluative','Affect','Judgement','Appreciation','Ambiguous']:\n",
        "        df2[col] = df2[col].astype(int)\n",
        "\n",
        "    # Align based on Text_ID + Sentence_ID\n",
        "    common_pairs = df_gold.merge(\n",
        "        df2[['Text_ID','Sentence_ID']],\n",
        "        on=['Text_ID','Sentence_ID'],\n",
        "        how='inner'\n",
        "    )[['Text_ID','Sentence_ID']]\n",
        "\n",
        "    df1_aligned = df_gold.merge(common_pairs, on=['Text_ID','Sentence_ID'], how='inner')\n",
        "    df2_aligned = df2.merge(common_pairs, on=['Text_ID','Sentence_ID'], how='inner')\n",
        "\n",
        "    # --- Compute Cohen's Kappa ---\n",
        "    kappa = cohen_kappa_score(df1_aligned[\"Evaluative\"], df2_aligned[\"Evaluative\"])\n",
        "\n",
        "    # --- Compute Krippendorff's Alpha ---\n",
        "    cols_to_check = ['Evaluative','Affect','Judgement','Appreciation','Ambiguous']\n",
        "    alphas = calculate_krippendorffs_alpha([df1_aligned, df2_aligned], cols_to_check)\n",
        "    filename = os.path.basename(file)\n",
        "    discipline, author = extract_disc_author(filename)\n",
        "\n",
        "    results.append({\n",
        "        \"discipline\": discipline,\n",
        "        \"author\": author,\n",
        "        \"cohen_kappa\": kappa,\n",
        "        **alphas\n",
        "    })\n",
        "\n",
        "\n",
        "# Convert to DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "print(results_df)\n",
        "\n",
        "# Optionally save\n",
        "results_df.to_excel(\"annotation_agreement_results.xlsx\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbaN3lVIro9g",
        "outputId": "1dc35a9a-6aee-45a5-98eb-d49fb32467be"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/output/output/Edu_Macie_Kilandi_merged.xlsx', '/content/output/output/Phi_Vanessa_Giesbrecht_merged.xlsx', '/content/output/output/Art_Paulina_Piotrowska_merged.xlsx', '/content/output/output/Bus_Leonie_Wessa_merged.xlsx', '/content/output/output/Med_Maria_SuarezPena_merged.xlsx', '/content/output/output/Edu_Elina_Arendt_merged.xlsx', '/content/output/output/Phi_Sema_Erkus_merged.xlsx', '/content/output/output/Sci_Chiara_Luisa_Büschel_merged.xlsx', '/content/output/output/Ent_Sofie_Wüller_merged.xlsx', '/content/output/output/Pol_Chrysoula_Choutouris_merged.xlsx', '/content/output/output/Bus_Oliwia_Wierzba_merged.xlsx', '/content/output/output/Med_Marta_Murcia_Tárraga_merged.xlsx', '/content/output/output/His_Yolanda_Ortega_merged.xlsx', '/content/output/output/Sci_Martin_Junge_merged.xlsx', '/content/output/output/Art_Oliwia_Wierzba_merged.xlsx', '/content/output/output/Ent_Laura_Bach_merged.xlsx', '/content/output/output/Psy_Fabian_Maurice_Heinze_merged.xlsx', '/content/output/output/Tech_Sean-Pascal_Kuttner_merged.xlsx', '/content/output/output/Pol_Ela_Erkasap_merged.xlsx', '/content/output/output/His_Marta_MartinezSerrano_merged.xlsx', '/content/output/output/Psy_Artem_Kilp_merged.xlsx']\n",
            "   discipline                 author  cohen_kappa  Evaluative    Affect  \\\n",
            "0         Edu          Macie_Kilandi    -0.064205   -0.093567 -0.030330   \n",
            "1         Phi     Vanessa_Giesbrecht    -0.091811   -0.088972 -0.112676   \n",
            "2         Art     Paulina_Piotrowska    -0.161290   -0.222222 -0.188272   \n",
            "3         Bus           Leonie_Wessa     0.071685    0.053704 -0.042857   \n",
            "4         Med       Maria_SuarezPena    -0.442786   -0.432770 -0.293155   \n",
            "5         Edu           Elina_Arendt    -0.133909   -0.148724  0.201389   \n",
            "6         Phi             Sema_Erkus    -0.023018   -0.010230 -0.215385   \n",
            "7         Sci   Chiara_Luisa_Büschel     0.064935    0.074219 -0.053333   \n",
            "8         Ent           Sofie_Wüller    -0.127168   -0.279070 -0.184615   \n",
            "9         Pol   Chrysoula_Choutouris    -0.010638   -0.014875 -0.067568   \n",
            "10        Bus         Oliwia_Wierzba    -0.113924   -0.111253 -0.067568   \n",
            "11        Med   Marta_Murcia_Tárraga    -0.322751   -0.380154  0.097143   \n",
            "12        His         Yolanda_Ortega     0.067797   -0.111253 -0.025974   \n",
            "13        Sci           Martin_Junge    -0.095890   -0.085165  0.227006   \n",
            "14        Art         Oliwia_Wierzba    -0.095890   -0.085165 -0.159329   \n",
            "15        Ent             Laura_Bach    -0.166667   -0.385965 -0.161765   \n",
            "16        Psy  Fabian_Maurice_Heinze    -0.035599   -0.053333  0.183697   \n",
            "17       Tech    Sean-Pascal_Kuttner     0.488491    0.494885 -0.067568   \n",
            "18        Pol            Ela_Erkasap    -0.023018   -0.010230 -0.097222   \n",
            "19        His  Marta_MartinezSerrano     0.109948    0.115866 -0.082192   \n",
            "20        Psy             Artem_Kilp     0.103870   -0.111253 -0.097222   \n",
            "\n",
            "    Judgement  Appreciation  Ambiguous  \n",
            "0   -0.215789     -0.115942   0.225352  \n",
            "1   -0.265446     -0.144928   0.000000  \n",
            "2    0.132045     -0.086694  -0.084507  \n",
            "3   -0.306905     -0.062835   0.000000  \n",
            "4   -0.097222     -0.274194  -0.012821  \n",
            "5    0.029777     -0.131148  -0.014706  \n",
            "6    0.008961     -0.097222  -0.025974  \n",
            "7   -0.053333      0.316017  -0.012821  \n",
            "8   -0.375000     -0.166667  -0.040541  \n",
            "9    0.074219     -0.091636  -0.161765  \n",
            "10  -0.158758     -0.024409  -0.012821  \n",
            "11  -0.083939     -0.238245  -0.012821  \n",
            "12   0.031863      0.171106  -0.012821  \n",
            "13  -0.179104      0.002296  -0.053333  \n",
            "14   0.078333      0.009404  -0.253968  \n",
            "15  -0.206545      0.031863  -0.082192  \n",
            "16   0.041083      0.147302   0.368000  \n",
            "17  -0.112676      0.337147  -0.039474  \n",
            "18  -0.125356     -0.159329  -0.196970  \n",
            "19   0.113891     -0.206545  -0.012821  \n",
            "20   0.225490      0.150538   0.480263  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For single file"
      ],
      "metadata": {
        "id": "7rjK4IQGzZs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#df = pd.read_excel(\"non-arg-phatic.xlsx\")\n",
        "\n",
        "df = pd.read_excel(\"/content/Gold_standard_Mirela.xlsx\")\n",
        "\n",
        "df2 = pd.read_excel(\"/content/Tech10_Sean-Pascal_Kuttner.xlsx\")"
      ],
      "metadata": {
        "id": "FGXPwTBAJ97D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "cWMEVR06OB_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.columns"
      ],
      "metadata": {
        "id": "GEqMtSQDXXHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df2.drop([ 'Uncertain', 'Notes'],axis = \"columns\")"
      ],
      "metadata": {
        "id": "3qhho2I4XdVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# CHECK WHAT OTHER LABELS ARE TRUE PER ANNOTATOR IF EVALUATIVE = 0\n",
        "\n",
        "df.columns\n",
        "\n",
        "df = df.fillna(0)\n",
        "#df2 = df2.drop(index=5)\n",
        "\n",
        "df['Evaluative'] = df['Evaluative'].astype(int)\n",
        "df['Affect'] = df['Affect'].astype(int)\n",
        "df['Judgement'] = df['Judgement'].astype(int)\n",
        "df['Appreciation'] = df['Appreciation'].astype(int)\n",
        "df['Ambiguous'] = df['Ambiguous'].astype(int)\n",
        "#df['Uncertain'] = df['Uncertain'].astype(int)\n"
      ],
      "metadata": {
        "id": "LzwMYn91Ll3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df2.fillna(0)\n",
        "\n",
        "df2['Evaluative'] = df2['Evaluative'].astype(int)\n",
        "df2['Affect'] = df2['Affect'].astype(int)\n",
        "df2['Judgement'] = df2['Judgement'].astype(int)\n",
        "df2['Appreciation'] = df2['Appreciation'].astype(int)\n",
        "df2['Ambiguous'] = df2['Ambiguous'].astype(int)\n",
        "#df2['Uncertain'] = df2['Uncertain'].astype(int)"
      ],
      "metadata": {
        "id": "ithmpiqpLpuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find common Text_ID + Sentence_ID pairs\n",
        "common_pairs = (\n",
        "    df.merge(\n",
        "        df2[['Text_ID', 'Sentence_ID']],\n",
        "        on=['Text_ID', 'Sentence_ID'],\n",
        "        how='inner'\n",
        "    )[['Text_ID', 'Sentence_ID']]\n",
        ")\n",
        "\n",
        "# Filter df\n",
        "df = df.merge(common_pairs, on=['Text_ID', 'Sentence_ID'], how='inner')\n",
        "\n",
        "# Filter df2\n",
        "df2 = df2.merge(common_pairs, on=['Text_ID', 'Sentence_ID'], how='inner')\n"
      ],
      "metadata": {
        "id": "W3OGwj6WSw8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "rTIPU3p6ZKHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2"
      ],
      "metadata": {
        "id": "vLxSJGCZQyVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis of Evaulative column = 0 and other columns = 1"
      ],
      "metadata": {
        "id": "aX_pZwQIRk_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df[(df['Evaluative'].isna()) | (df['Evaluative'] == \"\")]\n",
        "\n",
        "df2[(df2['Evaluative'].isna()) | (df2['Evaluative'] == \"\")]"
      ],
      "metadata": {
        "id": "DU9Ca7mfLfEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols_annotator_1  = ['Evaluative', 'Affect', 'Judgement', 'Appreciation', 'Ambiguous']\n",
        "cols_annotator_2  = ['Evaluative', 'Affect', 'Judgement', 'Appreciation', 'Ambiguous']"
      ],
      "metadata": {
        "id": "ksRBt77pLrbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter rows where Evaluative == 0 for annotator 1\n",
        "df_0_eval_1 = df[df['Evaluative'] == 0]"
      ],
      "metadata": {
        "id": "MRizkNuHLtu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count how many times each of the other columns == 1 in those rows\n",
        "counts_1 = df_0_eval_1[cols_annotator_1].apply(lambda col: (col == 1).sum())\n",
        "counts_1"
      ],
      "metadata": {
        "id": "iz4bOQ8xLu6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Repeat for annotator 2\n",
        "df_0_eval_2 = df[df['Evaluative'] == 0]\n",
        "counts_2 = df_0_eval_2[cols_annotator_2].apply(lambda col: (col == 1).sum())"
      ],
      "metadata": {
        "id": "LcyRxmywLxgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Annotator 1 - counts where Evaluative=0 and other columns=1:\\n\", counts_1)\n",
        "print(\"Annotator 2 - counts where Evaluative=0 and other columns=1:\\n\", counts_2)"
      ],
      "metadata": {
        "id": "Ao6WiE1vLywB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis of Evaulative column = 1"
      ],
      "metadata": {
        "id": "sEyNsIDHRumF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter rows where Evaluative == 1 for annotator 1\n",
        "df_0_eval_1 = df[df['Evaluative'] == 1]"
      ],
      "metadata": {
        "id": "37YPPq-mL0IW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count how many times each of the other columns == 1 in those rows\n",
        "counts_1 = df_0_eval_1[cols_annotator_1].apply(lambda col: (col == 1).sum())\n",
        "counts_1"
      ],
      "metadata": {
        "id": "DBslTlasR0IB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Repeat for annotator 2\n",
        "df_0_eval_2 = df2[df2['Evaluative'] == 1]\n",
        "counts_2 = df_0_eval_2[cols_annotator_2].apply(lambda col: (col == 1).sum())\n",
        "counts_2"
      ],
      "metadata": {
        "id": "5Chy84e1R5xr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Annotator 1 - counts where Evaluative=1 and other columns=1:\\n\", counts_1)\n",
        "print(\"Annotator 2 - counts where Evaluative=1 and other columns=1:\\n\", counts_2)"
      ],
      "metadata": {
        "id": "ZuvGHMMBR_6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Berechnung: Cohens_Kappa"
      ],
      "metadata": {
        "id": "wp4yWqDpMGNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import cohen_kappa_score\n"
      ],
      "metadata": {
        "id": "hppkQePXMIRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"# Filter out the placeholder values before calculating the kappa score\n",
        "df_anno1_filtered = df_anno1[df_anno1[\"Evaluative\"] != -1]\n",
        "df2_anno2_filtered = df2_anno2[df2_anno2[\"Evaluative\"] != -1]\n",
        "\n",
        "# Ensure both dataframes have the same indices after filtering\n",
        "common_indices = df_anno1_filtered.index.intersection(df2_anno2_filtered.index)\n",
        "df_anno1_aligned = df_anno1_filtered.loc[common_indices]\n",
        "df2_anno2_aligned = df2_anno2_filtered.loc[common_indices]\"\"\""
      ],
      "metadata": {
        "id": "hFldTRn-MJjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your columns are named \"mobilisierung\" and \"informativ\" (adjust as necessary)\n",
        "kappa_score = cohen_kappa_score(df[\"Evaluative\"], df2[\"Evaluative\"])\n",
        "print(f\"Cohen's Kappa: {kappa_score}\")"
      ],
      "metadata": {
        "id": "7lR4XAN7MKsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Kappa Kuck und Knierim: Cohen's Kappa: 0.6156981445684476\n",
        "# Kappa Knierim und GPT4: Cohen's Kappa: 0.35816326807273824\n",
        "# Kappa Kuck und GPT4: Cohen's Kappa: 0.38653552825615034"
      ],
      "metadata": {
        "id": "gC6Y4dElML4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filter the empty string-lines to calculate agreement on whether the sentence is evaluative\n",
        "\"\"\"df[df['Evaluative'] == 1]\n",
        "df2[df2['Evaluative'] == 1]\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "lzzoXJQTMN1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lq_9nAXCJq7T"
      },
      "outputs": [],
      "source": [
        "import krippendorff\n",
        "import numpy as np\n",
        "\n",
        "def calculate_krippendorffs_alpha(df_list, columns, evaluative_col='Evaluative'):\n",
        "    \"\"\"\n",
        "    Calculates Krippendorff's Alpha for given columns, considering only rows\n",
        "    where evaluative_col == 1. Assumes missing data is marked as -1.\n",
        "\n",
        "    Parameters:\n",
        "        df_list (list of pd.DataFrame): List of annotator DataFrames (one per annotator).\n",
        "        columns (list): List of column names to calculate alpha on.\n",
        "        evaluative_col (str): Column name indicating 'true' evaluative lines.\n",
        "\n",
        "    Returns:\n",
        "        dict: column_name -> Krippendorff's Alpha score\n",
        "    \"\"\"\n",
        "    alphas = {}\n",
        "\n",
        "    # Combine DataFrames on index (assumes they are aligned)\n",
        "    # Create a matrix of shape (num_annotators, num_items)\n",
        "    for col in columns:\n",
        "        # Filter rows where evaluative_col == 1 for all annotators\n",
        "        mask = np.array([df[evaluative_col] == 1 for df in df_list]).all(axis=0)\n",
        "\n",
        "        # Collect data from all annotators for this column, filtered by mask\n",
        "        data = []\n",
        "        for df in df_list:\n",
        "            # Use -1 as missing, krippendorff expects np.nan for missing, so convert\n",
        "            col_data = df.loc[mask, col].replace(-1, np.nan).to_numpy()\n",
        "            data.append(col_data)\n",
        "\n",
        "        # Convert to numpy array of shape (num_annotators, num_items)\n",
        "        data = np.array(data)\n",
        "\n",
        "        # Check if there is more than one unique value in the data for this column\n",
        "        unique_values = np.unique(data[~np.isnan(data)])\n",
        "        if len(unique_values) <= 1:\n",
        "            print(f\"Skipping {col}: Only one unique value ({unique_values}) after filtering for Evaluative=1.\")\n",
        "            continue\n",
        "\n",
        "        # Calculate Krippendorff's Alpha (nominal metric)\n",
        "        alpha = krippendorff.alpha(reliability_data=data, level_of_measurement='nominal')\n",
        "        alphas[col] = alpha\n",
        "\n",
        "    return alphas\n",
        "\n",
        "df_list = [df, df2]\n",
        "cols_to_check = ['Evaluative','Affect', 'Judgement', 'Appreciation', 'Ambiguous']\n",
        "\n",
        "alphas = calculate_krippendorffs_alpha(df_list, cols_to_check)\n",
        "for col, alpha in alphas.items():\n",
        "    print(f\"Krippendorff's Alpha for {col}: {alpha:.3f}\")\n",
        "\n"
      ]
    }
  ]
}