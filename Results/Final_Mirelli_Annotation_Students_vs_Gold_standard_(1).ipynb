{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!unzip output.zip -d /content"
      ],
      "metadata": {
        "id": "Sm6n67H8XHW8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b77f3c2b-1365-4701-bda5-d89c94d0c3b6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  output.zip\n",
            "   creating: /content/output/\n",
            "   creating: /content/output/output/\n",
            "  inflating: /content/output/output/Art5_Oliwia_Wierzbaa.xlsx  \n",
            "  inflating: /content/output/output/Art5_Paulina_Piotrowska.xlsx  \n",
            "  inflating: /content/output/output/Art6_Oliwia_Wierzbaa.xlsx  \n",
            "  inflating: /content/output/output/Art6_Paulina_Piotrowska.xlsx  \n",
            "  inflating: /content/output/output/Bus11_Leonie_Wessa.xlsx  \n",
            "  inflating: /content/output/output/Bus11_Oliwia_Wierzba.xlsx  \n",
            "  inflating: /content/output/output/Bus14_Leonie_Wessa.xlsx  \n",
            "  inflating: /content/output/output/Bus14_Oliwia_Wierzba.xlsx  \n",
            "  inflating: /content/output/output/Edu2_Elina_Arendt.xlsx  \n",
            "  inflating: /content/output/output/Edu2_Macie_Kilandi.xlsx  \n",
            "  inflating: /content/output/output/Edu6_Elina_Arendt.xlsx  \n",
            "  inflating: /content/output/output/Edu6_Macie_Kilandi.xlsx  \n",
            "  inflating: /content/output/output/Ent5_Laura_Bach.xlsx  \n",
            "  inflating: /content/output/output/Ent5_Sofie_Wüller.xlsx  \n",
            "  inflating: /content/output/output/Ent8_Laura_Bach.xlsx  \n",
            "  inflating: /content/output/output/Ent8_Sofie_Wüller.xlsx  \n",
            "  inflating: /content/output/output/His13_Marta_MartinezSerrano.xlsx  \n",
            "  inflating: /content/output/output/His13_Yolanda_Ortega.xlsx  \n",
            "  inflating: /content/output/output/His5_Marta_MartinezSerrano.xlsx  \n",
            "  inflating: /content/output/output/His5_Yolanda_Ortega.xlsx  \n",
            "  inflating: /content/output/output/Med15_Maria_SuarezPena.xlsx  \n",
            "  inflating: /content/output/output/Med15_Marta_Tarraga.xlsx  \n",
            "  inflating: /content/output/output/Med9_Maria_SuarezPena.xlsx  \n",
            "  inflating: /content/output/output/Med9_Marta_Tarraga.xlsx  \n",
            "  inflating: /content/output/output/Phi3_Sema_Erkus.xlsx  \n",
            "  inflating: /content/output/output/Phi3_Vanessa_Giesbrecht.xlsx  \n",
            "  inflating: /content/output/output/Phi8_Sema_Erkus.xlsx  \n",
            "  inflating: /content/output/output/Phi8_Vanessa_Giesbrecht.xlsx  \n",
            "  inflating: /content/output/output/Pol2_Chrysoula_Choutouris.xlsx  \n",
            "  inflating: /content/output/output/Pol2_Ela_Erkasap.xlsx  \n",
            "  inflating: /content/output/output/Pol9_Chrysoula_Choutouris.xlsx  \n",
            "  inflating: /content/output/output/Pol9_Ela_Erkasap.xlsx  \n",
            "  inflating: /content/output/output/Psy5_Artem_Kilp.xlsx  \n",
            "  inflating: /content/output/output/Psy5_Fabian_Heinze.xlsx  \n",
            "  inflating: /content/output/output/Psy8_Artem_Kilp.xlsx  \n",
            "  inflating: /content/output/output/Psy8_Fabian_Heinze.xlsx  \n",
            "  inflating: /content/output/output/Sci10_Chiara_Büschel.xlsx  \n",
            "  inflating: /content/output/output/Sci10_Martin_Junge.xlsx  \n",
            "  inflating: /content/output/output/Sci7_Chiara_Büschel.xlsx  \n",
            "  inflating: /content/output/output/Sci7_Martin_Junge.xlsx  \n",
            "  inflating: /content/output/output/Tech10_Josefine_Baer.xlsx  \n",
            "  inflating: /content/output/output/Tech10_Sean-Pascal_Kuttner.xlsx  \n",
            "  inflating: /content/output/output/Tech21_Josefine_Baer.xlsx  \n",
            "  inflating: /content/output/output/Tech21_Sean-Pascal_Kuttner.xlsx  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install krippendorff"
      ],
      "metadata": {
        "id": "I0MbPtFzMT-Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccc266c1-ce99-4bd1-ddf1-6910eda15133"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting krippendorff\n",
            "  Downloading krippendorff-0.8.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.21 in /usr/local/lib/python3.12/dist-packages (from krippendorff) (2.0.2)\n",
            "Downloading krippendorff-0.8.2-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: krippendorff\n",
            "Successfully installed krippendorff-0.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "import krippendorff\n",
        "import numpy as np\n",
        "import glob\n",
        "import os"
      ],
      "metadata": {
        "id": "E7MBP1c7jZGm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_disc_author(filename):\n",
        "    \"\"\"\n",
        "    From: 'Edu_Macie_Kilandi_merged.xlsx'\n",
        "    → discipline='Edu'\n",
        "    → author='Macie_Kilandi'\n",
        "    (removes 'merged' and file extension)\n",
        "    \"\"\"\n",
        "    base = os.path.splitext(filename)[0]         # remove .xlsx\n",
        "    base = base.replace(\"_merged\", \"\")           # remove merged\n",
        "    parts = base.split(\"_\")\n",
        "\n",
        "    discipline = parts[0]                        # first token\n",
        "    author = \"_\".join(parts[1:])                 # everything after\n",
        "\n",
        "    return discipline, author\n"
      ],
      "metadata": {
        "id": "ljfp3vTdjauM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def calculate_krippendorffs_alpha(df_list, columns):\n",
        "    \"\"\"\n",
        "    Krippendorff's alpha:\n",
        "    - Evaluative: computed on all rows\n",
        "    - Other columns: computed ONLY where Evaluative == 1 for ALL annotators\n",
        "    \"\"\"\n",
        "    alphas = {}\n",
        "\n",
        "    for col in columns:\n",
        "        data = []\n",
        "\n",
        "        # mask logic\n",
        "        if col == \"Evaluative\":\n",
        "            mask = np.ones(len(df_list[0]), dtype=bool)\n",
        "        else:\n",
        "            # ONLY rows where all annotators marked Evaluative == 1\n",
        "            mask = np.logical_and.reduce(\n",
        "                [df[\"Evaluative\"] == 1 for df in df_list]\n",
        "            )\n",
        "\n",
        "        for df in df_list:\n",
        "            col_data = df.loc[mask, col].replace(-1, np.nan).to_numpy()\n",
        "            data.append(col_data)\n",
        "\n",
        "        data = np.array(data)\n",
        "\n",
        "        # skip if no usable data\n",
        "        if data.shape[1] == 0:\n",
        "            alphas[col] = np.nan\n",
        "            continue\n",
        "\n",
        "        # skip if only one unique value\n",
        "        unique_vals = np.unique(data[~np.isnan(data)])\n",
        "        if len(unique_vals) <= 1:\n",
        "            alphas[col] = np.nan\n",
        "            continue\n",
        "\n",
        "        alphas[col] = krippendorff.alpha(\n",
        "            reliability_data=data,\n",
        "            level_of_measurement=\"nominal\"\n",
        "        )\n",
        "\n",
        "    return alphas\n"
      ],
      "metadata": {
        "id": "CYmbjKUgjdF8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FOR EACH FILE\n",
        "results = []\n",
        "\n",
        "common_dfs = []\n",
        "\n",
        "gold_file = \"/content/Gold_standard_Mirela.xlsx\"\n",
        "df_gold = pd.read_excel(gold_file)\n",
        "\n",
        "# Normalize gold file\n",
        "df_gold = df_gold.fillna(0)\n",
        "\n",
        "\n",
        "df_gold = df_gold.fillna(0)\n",
        "#df_gold2 = df_gold2.drop(index=5)\n",
        "\n",
        "#Just to be sure of int values\n",
        "df_gold['Evaluative'] = df_gold['Evaluative'].astype(int)\n",
        "df_gold['Affect'] = df_gold['Affect'].astype(int)\n",
        "df_gold['Judgement'] = df_gold['Judgement'].astype(int)\n",
        "df_gold['Appreciation'] = df_gold['Appreciation'].astype(int)\n",
        "df_gold['Ambiguous'] = df_gold['Ambiguous'].astype(int)\n",
        "#df_gold['Uncertain'] = df_gold['Uncertain'].astype(int)\n",
        "for col in ['Evaluative','Affect','Judgement','Appreciation','Ambiguous']:\n",
        "    df_gold[col] = df_gold[col].astype(int)\n",
        "\n",
        "# Path where student files live\n",
        "student_files = glob.glob(\"/content/output/output/*.xlsx\")\n",
        "print(student_files)\n",
        "\n",
        "\n",
        "for file in student_files:\n",
        "    df2 = pd.read_excel(file)\n",
        "\n",
        "    # Clean student file\n",
        "    # Identify any column whose name equals 'uncertain' ignoring case sometimes it was 'Uncertain'\n",
        "    uncertain_cols = [c for c in df2.columns if c.lower() == 'uncertain']\n",
        "\n",
        "    # Remove rows where uncertain == 1 cause that result is not useful for us!!\n",
        "    for col in uncertain_cols:\n",
        "        df2 = df2[df2[col] != 1]\n",
        "\n",
        "    df2 = df2.drop(['uncertain','Notes'], axis=1, errors='ignore').fillna(0)\n",
        "    for col in ['Evaluative','Affect','Judgement','Appreciation','Ambiguous']:\n",
        "        df2[col] = df2[col].astype(int)\n",
        "\n",
        "    df2 = df2.fillna(0)\n",
        "\n",
        "    df2['Evaluative'] = df2['Evaluative'].astype(int)\n",
        "    df2['Affect'] = df2['Affect'].astype(int)\n",
        "    df2['Judgement'] = df2['Judgement'].astype(int)\n",
        "    df2['Appreciation'] = df2['Appreciation'].astype(int)\n",
        "    df2['Ambiguous'] = df2['Ambiguous'].astype(int)\n",
        "    #df2['Uncertain'] = df2['Uncertain'].astype(int)\n",
        "\n",
        "    # Align based on Text_ID + Sentence_ID\n",
        "    common_pairs = df_gold.merge(\n",
        "        df2[['Text_ID','Sentence_ID']],\n",
        "        on=['Text_ID','Sentence_ID'],\n",
        "        how='inner'\n",
        "    )[['Text_ID','Sentence_ID']]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    df1_aligned = df_gold.merge(common_pairs, on=['Text_ID','Sentence_ID'], how='inner')\n",
        "    df2_aligned = df2.merge(common_pairs, on=['Text_ID','Sentence_ID'], how='inner')\n",
        "\n",
        "    # SORTING IS VERY IMPORTANT OTHERWISE IT JUST CHECKS ON WHATEVER ORDER IT OCCURS\n",
        "    df1_aligned = df1_aligned.sort_values(['Text_ID','Sentence_ID']).reset_index(drop=True)\n",
        "    df2_aligned = df2_aligned.sort_values(['Text_ID','Sentence_ID']).reset_index(drop=True)\n",
        "\n",
        "    # --- Compute Cohen's Kappa ---\n",
        "    kappa = cohen_kappa_score(df1_aligned[\"Evaluative\"], df2_aligned[\"Evaluative\"])\n",
        "\n",
        "    # --- Compute Krippendorff's Alpha ---\n",
        "    cols_to_check = ['Evaluative','Affect','Judgement','Appreciation','Ambiguous']\n",
        "    alphas = calculate_krippendorffs_alpha([df1_aligned, df2_aligned], cols_to_check)\n",
        "    filename = os.path.basename(file)\n",
        "    discipline, author = extract_disc_author(filename)\n",
        "\n",
        "    results.append({\n",
        "        \"discipline\": discipline,\n",
        "        \"author\": author,\n",
        "        \"cohen_kappa\": kappa,\n",
        "        **alphas\n",
        "    })\n",
        "\n",
        "\n",
        "    # ---------------------------------------------\n",
        "    # Build common gold–student dataframe\n",
        "    # ---------------------------------------------\n",
        "    common_df = df1_aligned.merge(\n",
        "    df2_aligned,\n",
        "    on=['Text_ID', 'Sentence_ID'],\n",
        "    how='inner',\n",
        "    suffixes=('_gold', '_student')\n",
        "    )\n",
        "\n",
        "    # Add metadata columns\n",
        "    common_df.insert(0, 'author', author)\n",
        "    common_df.insert(0, 'discipline', discipline)\n",
        "\n",
        "    common_dfs.append(common_df)\n",
        "\n",
        "\n",
        "# Convert to DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_excel(\"annotation_agreement_results.xlsx\", index=False)\n",
        "print(results_df)\n",
        "\n",
        "final_common_df = pd.concat(common_dfs, ignore_index=True)\n",
        "\n",
        "assert not final_common_df.duplicated(\n",
        "    ['author', 'Text_ID', 'Sentence_ID']\n",
        ").any()\n",
        "\n",
        "final_common_df.to_excel(\n",
        "    \"common_gold_student_annotations.xlsx\",\n",
        "    index=False\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbaN3lVIro9g",
        "outputId": "c1aca3b8-d833-4ee0-ec05-bb0914ca7ff1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/output/output/Edu2_Elina_Arendt.xlsx', '/content/output/output/Art6_Paulina_Piotrowska.xlsx', '/content/output/output/His13_Marta_MartinezSerrano.xlsx', '/content/output/output/Tech10_Josefine_Baer.xlsx', '/content/output/output/Pol9_Ela_Erkasap.xlsx', '/content/output/output/Ent5_Sofie_Wüller.xlsx', '/content/output/output/Art6_Oliwia_Wierzbaa.xlsx', '/content/output/output/His5_Yolanda_Ortega.xlsx', '/content/output/output/Phi8_Sema_Erkus.xlsx', '/content/output/output/Tech10_Sean-Pascal_Kuttner.xlsx', '/content/output/output/Pol2_Chrysoula_Choutouris.xlsx', '/content/output/output/Med9_Maria_SuarezPena.xlsx', '/content/output/output/Tech21_Sean-Pascal_Kuttner.xlsx', '/content/output/output/Bus14_Leonie_Wessa.xlsx', '/content/output/output/Edu2_Macie_Kilandi.xlsx', '/content/output/output/Pol9_Chrysoula_Choutouris.xlsx', '/content/output/output/His13_Yolanda_Ortega.xlsx', '/content/output/output/Psy5_Fabian_Heinze.xlsx', '/content/output/output/Sci7_Chiara_Büschel.xlsx', '/content/output/output/Sci10_Martin_Junge.xlsx', '/content/output/output/Sci10_Chiara_Büschel.xlsx', '/content/output/output/Ent5_Laura_Bach.xlsx', '/content/output/output/Phi3_Sema_Erkus.xlsx', '/content/output/output/Bus11_Leonie_Wessa.xlsx', '/content/output/output/Edu6_Elina_Arendt.xlsx', '/content/output/output/Psy8_Fabian_Heinze.xlsx', '/content/output/output/Med15_Maria_SuarezPena.xlsx', '/content/output/output/Med15_Marta_Tarraga.xlsx', '/content/output/output/Phi3_Vanessa_Giesbrecht.xlsx', '/content/output/output/Tech21_Josefine_Baer.xlsx', '/content/output/output/Bus14_Oliwia_Wierzba.xlsx', '/content/output/output/Edu6_Macie_Kilandi.xlsx', '/content/output/output/Art5_Paulina_Piotrowska.xlsx', '/content/output/output/Psy8_Artem_Kilp.xlsx', '/content/output/output/Art5_Oliwia_Wierzbaa.xlsx', '/content/output/output/Bus11_Oliwia_Wierzba.xlsx', '/content/output/output/Phi8_Vanessa_Giesbrecht.xlsx', '/content/output/output/His5_Marta_MartinezSerrano.xlsx', '/content/output/output/Pol2_Ela_Erkasap.xlsx', '/content/output/output/Med9_Marta_Tarraga.xlsx', '/content/output/output/Ent8_Laura_Bach.xlsx', '/content/output/output/Psy5_Artem_Kilp.xlsx', '/content/output/output/Sci7_Martin_Junge.xlsx', '/content/output/output/Ent8_Sofie_Wüller.xlsx']\n",
            "   discipline                 author  cohen_kappa  Evaluative    Affect  \\\n",
            "0        Edu2           Elina_Arendt     0.377049    0.383333  0.431818   \n",
            "1        Art6     Paulina_Piotrowska     0.600000    0.610000  0.727273   \n",
            "2       His13  Marta_MartinezSerrano     0.400000    0.357143       NaN   \n",
            "3      Tech10          Josefine_Baer     0.313725    0.315789  0.606061   \n",
            "4        Pol9            Ela_Erkasap     0.130435    0.142857 -0.133333   \n",
            "5        Ent5           Sofie_Wüller     0.103774   -0.027778  1.000000   \n",
            "6        Art6        Oliwia_Wierzbaa     0.600000    0.606061  0.527778   \n",
            "7        His5         Yolanda_Ortega     0.100000   -0.100313       NaN   \n",
            "8        Phi8             Sema_Erkus     0.431818    0.444444  0.125000   \n",
            "9      Tech10    Sean-Pascal_Kuttner     0.693878    0.700767  0.406250   \n",
            "10       Pol2   Chrysoula_Choutouris     0.191919    0.212121  0.000000   \n",
            "11       Med9       Maria_SuarezPena     0.166667    0.155844 -0.588235   \n",
            "12     Tech21    Sean-Pascal_Kuttner     0.875000    0.877743 -0.125000   \n",
            "13      Bus14           Leonie_Wessa     0.604167    0.614583  1.000000   \n",
            "14       Edu2          Macie_Kilandi     0.577778    0.574713  0.305556   \n",
            "15       Pol9   Chrysoula_Choutouris     0.418605    0.388715 -0.095238   \n",
            "16      His13         Yolanda_Ortega     0.237288    0.102302  0.000000   \n",
            "17       Psy5          Fabian_Heinze     0.384615    0.390625  0.765217   \n",
            "18       Sci7         Chiara_Büschel     0.509804    0.511278  0.606061   \n",
            "19      Sci10           Martin_Junge     0.062500    0.085938       NaN   \n",
            "20      Sci10         Chiara_Büschel     0.255319    0.222222       NaN   \n",
            "21       Ent5             Laura_Bach     0.250000    0.120301  0.592593   \n",
            "22       Phi3             Sema_Erkus     0.500000    0.511278  0.350000   \n",
            "23      Bus11           Leonie_Wessa     0.162791    0.090909  0.000000   \n",
            "24       Edu6           Elina_Arendt     0.555556    0.550725  0.620000   \n",
            "25       Psy8          Fabian_Heinze    -0.136364   -0.160714  0.738462   \n",
            "26      Med15       Maria_SuarezPena     0.178082    0.085938  0.000000   \n",
            "27      Med15          Marta_Tarraga     0.150943    0.120301  0.571429   \n",
            "28       Phi3     Vanessa_Giesbrecht     0.393939    0.409091  0.592593   \n",
            "29     Tech21          Josefine_Baer     0.238095    0.187500 -0.750000   \n",
            "30      Bus14         Oliwia_Wierzba    -0.012658   -0.040000  1.000000   \n",
            "31       Edu6          Macie_Kilandi     0.545455    0.535714  0.342857   \n",
            "32       Art5     Paulina_Piotrowska     0.159292   -0.051136  0.592593   \n",
            "33       Psy8             Artem_Kilp    -0.101695   -0.444444       NaN   \n",
            "34       Art5        Oliwia_Wierzbaa     0.240506    0.220000 -0.210526   \n",
            "35      Bus11         Oliwia_Wierzba    -0.250000   -0.218750       NaN   \n",
            "36       Phi8     Vanessa_Giesbrecht     0.400000    0.390625 -0.133333   \n",
            "37       His5  Marta_MartinezSerrano     0.300000    0.301790  0.000000   \n",
            "38       Pol2            Ela_Erkasap     0.405941    0.415000  0.000000   \n",
            "39       Med9          Marta_Tarraga     0.272727    0.235294  0.194444   \n",
            "40       Ent8             Laura_Bach     0.083333   -0.075188 -0.800000   \n",
            "41       Psy5             Artem_Kilp     0.250000    0.120301  1.000000   \n",
            "42       Sci7           Martin_Junge     0.603960    0.610000 -0.363636   \n",
            "43       Ent8           Sofie_Wüller     0.181818    0.102302 -0.083333   \n",
            "\n",
            "    Judgement  Appreciation  Ambiguous  \n",
            "0    0.545455      0.812030        NaN  \n",
            "1    1.000000      0.181818  -0.250000  \n",
            "2    0.424242      0.604167   0.000000  \n",
            "3   -0.083333     -0.181818  -0.083333  \n",
            "4    0.370370     -0.416667  -0.307692  \n",
            "5    0.250000      0.640000   0.000000  \n",
            "6    0.150000      0.150000   0.055556  \n",
            "7         NaN           NaN        NaN  \n",
            "8    0.102564     -0.166667   0.000000  \n",
            "9   -0.187500      0.240000   0.627451  \n",
            "10  -0.444444     -0.326531  -0.181818  \n",
            "11  -0.285714      0.437500  -0.038462  \n",
            "12  -0.080000      0.250000   0.000000  \n",
            "13  -0.035714     -0.035714        NaN  \n",
            "14   0.687500      0.285714  -0.041667  \n",
            "15   0.281250     -0.125874  -0.277778  \n",
            "16   0.204082     -0.326531   0.000000  \n",
            "17  -0.350000      0.278075  -0.038462  \n",
            "18  -0.326531     -0.083333  -0.083333  \n",
            "19        NaN           NaN        NaN  \n",
            "20  -0.250000     -0.250000        NaN  \n",
            "21   0.388889      0.312500   0.000000  \n",
            "22   0.458333     -0.181818  -0.083333  \n",
            "23  -0.326531     -0.625000   0.000000  \n",
            "24   0.424242      1.000000   0.000000  \n",
            "25   0.392857      0.779221   1.000000  \n",
            "26   0.000000           NaN        NaN  \n",
            "27   1.000000      0.640000        NaN  \n",
            "28   0.312500      0.000000        NaN  \n",
            "29  -0.400000      0.000000        NaN  \n",
            "30  -0.256410     -0.214876        NaN  \n",
            "31   0.033613     -0.095238   0.273684  \n",
            "32   0.000000      0.312500  -0.100000  \n",
            "33        NaN           NaN        NaN  \n",
            "34   0.273684      0.281250  -0.078125  \n",
            "35   0.000000      0.000000        NaN  \n",
            "36   0.790123      0.779221   0.000000  \n",
            "37   0.000000     -0.190476        NaN  \n",
            "38  -0.181818     -0.083333  -0.300000  \n",
            "39   0.028708      0.223214   0.000000  \n",
            "40   0.571429      1.000000  -0.500000  \n",
            "41   0.312500      1.000000  -0.100000  \n",
            "42   0.500000      0.500000   0.181818  \n",
            "43  -0.326531      0.606061  -0.083333  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Author level\n",
        "\n",
        "LABEL_COLS = [\n",
        "    'Evaluative',\n",
        "    'Affect',\n",
        "    'Judgement',\n",
        "    'Appreciation',\n",
        "    'Ambiguous'\n",
        "]\n",
        "gold_label_cols = [c for c in final_common_df.columns if c.endswith('_gold')]\n",
        "student_label_cols = [c for c in final_common_df.columns if c.endswith('_student')]\n",
        "author_results = []\n",
        "\n",
        "for author, df_author in final_common_df.groupby('author'):\n",
        "\n",
        "    # ---------------------------------------------\n",
        "    # Cohen’s Kappa (Evaluative)\n",
        "    # ---------------------------------------------\n",
        "\n",
        "    kappa = cohen_kappa_score(\n",
        "        df_author['Evaluative_gold'],\n",
        "        df_author['Evaluative_student']\n",
        "    )\n",
        "\n",
        "    # ---------------------------------------------\n",
        "    # Krippendorff’s Alpha\n",
        "    # ---------------------------------------------\n",
        "\n",
        "    df_gold_author = df_author[[c for c in gold_label_cols]].copy()\n",
        "    df_student_author = df_author[[c for c in student_label_cols]].copy()\n",
        "\n",
        "    # Remove suffixes so column names match\n",
        "    df_gold_author.columns = [c.replace('_gold', '') for c in df_gold_author.columns]\n",
        "    df_student_author.columns = [c.replace('_student', '') for c in df_student_author.columns]\n",
        "\n",
        "    alphas = calculate_krippendorffs_alpha(\n",
        "        [df_gold_author, df_student_author],\n",
        "        LABEL_COLS\n",
        "    )\n",
        "\n",
        "    author_results.append({\n",
        "        'author': author,\n",
        "        'disciplines_merged': sorted(df_author['discipline'].unique().tolist()),\n",
        "        'n_sentences': len(df_author),\n",
        "        'cohen_kappa': kappa,\n",
        "        **alphas\n",
        "    })\n"
      ],
      "metadata": {
        "id": "qsS3z49Stnyb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "author_results_df = pd.DataFrame(author_results)\n",
        "author_results_df.to_excel(\n",
        "    \"annotation_agreement_results_by_author.xlsx\",\n",
        "    index=False\n",
        ")\n",
        "\n",
        "print(author_results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tq5Shq7gtPQj",
        "outputId": "c92870dc-0fad-47ba-bb71-fe632054006a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   author disciplines_merged  n_sentences  cohen_kappa  \\\n",
            "0              Artem_Kilp       [Psy5, Psy8]           40     0.103870   \n",
            "1          Chiara_Büschel      [Sci10, Sci7]           40     0.376623   \n",
            "2    Chrysoula_Choutouris       [Pol2, Pol9]           40     0.308511   \n",
            "3             Ela_Erkasap       [Pol2, Pol9]           40     0.283887   \n",
            "4            Elina_Arendt       [Edu2, Edu6]           35     0.470842   \n",
            "5           Fabian_Heinze       [Psy5, Psy8]           40     0.093851   \n",
            "6           Josefine_Baer   [Tech10, Tech21]           40     0.250000   \n",
            "7              Laura_Bach       [Ent5, Ent8]           40     0.166667   \n",
            "8            Leonie_Wessa     [Bus11, Bus14]           37     0.336918   \n",
            "9           Macie_Kilandi       [Edu2, Edu6]           39     0.561798   \n",
            "10       Maria_SuarezPena      [Med15, Med9]           40     0.452736   \n",
            "11  Marta_MartinezSerrano      [His13, His5]           40     0.319372   \n",
            "12          Marta_Tarraga      [Med15, Med9]           40     0.312169   \n",
            "13           Martin_Junge      [Sci10, Sci7]           40     0.452055   \n",
            "14         Oliwia_Wierzba     [Bus11, Bus14]           40    -0.012658   \n",
            "15        Oliwia_Wierzbaa       [Art5, Art6]           40     0.452055   \n",
            "16     Paulina_Piotrowska       [Art5, Art6]           39     0.322581   \n",
            "17    Sean-Pascal_Kuttner   [Tech10, Tech21]           40     0.795396   \n",
            "18             Sema_Erkus       [Phi3, Phi8]           40     0.488491   \n",
            "19           Sofie_Wüller       [Ent5, Ent8]           39     0.143353   \n",
            "20     Vanessa_Giesbrecht       [Phi3, Phi8]           40     0.404467   \n",
            "21         Yolanda_Ortega      [His13, His5]           40     0.237288   \n",
            "\n",
            "    Evaluative    Affect  Judgement  Appreciation  Ambiguous  \n",
            "0    -0.111253  1.000000   0.312500      1.000000  -0.100000  \n",
            "1     0.382812  0.627451  -0.343434     -0.140000  -0.055556  \n",
            "2     0.305612 -0.088235  -0.024615     -0.233333  -0.275862  \n",
            "3     0.292839 -0.107143   0.225000     -0.230159  -0.347826  \n",
            "4     0.463929  0.598214   0.488636      0.864865   0.000000  \n",
            "5     0.078333  0.750000  -0.102941      0.464286   0.464286  \n",
            "6     0.255185  0.000000  -0.235294      0.300000  -0.050000  \n",
            "7     0.010025 -0.125000   0.461538      0.562500  -0.235294  \n",
            "8     0.324074  0.650407  -0.157350     -0.243802   0.000000  \n",
            "9     0.549708  0.319444   0.388592      0.125000   0.186047  \n",
            "10    0.456535 -0.611111  -0.318182      0.462963  -0.035714  \n",
            "11    0.323897  0.000000   0.222222      0.222222   0.000000  \n",
            "12    0.282320  0.301075   0.222222      0.315789   0.000000  \n",
            "13    0.457418 -0.307692   0.575000      0.575000   0.215385  \n",
            "14   -0.010230  1.000000  -0.250000     -0.190476        NaN  \n",
            "15    0.457418  0.324706   0.291358      0.211538  -0.045918  \n",
            "16    0.287037  0.662500   0.765217      0.210526  -0.227273  \n",
            "17    0.797954  0.194444  -0.074074      0.306220   0.442308  \n",
            "18    0.494885  0.192308   0.222222     -0.206897  -0.060606  \n",
            "19    0.027907  0.281250  -0.125874      0.640625  -0.095238  \n",
            "20    0.406015  0.194444   0.606335      0.670455   0.000000  \n",
            "21    0.090793  0.000000   0.285714     -0.190476   0.000000  \n"
          ]
        }
      ]
    }
  ]
}