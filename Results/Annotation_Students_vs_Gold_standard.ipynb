{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!unzip output.zip -d /content"
      ],
      "metadata": {
        "id": "Sm6n67H8XHW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install krippendorff"
      ],
      "metadata": {
        "id": "I0MbPtFzMT-Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccc266c1-ce99-4bd1-ddf1-6910eda15133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting krippendorff\n",
            "  Downloading krippendorff-0.8.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.21 in /usr/local/lib/python3.12/dist-packages (from krippendorff) (2.0.2)\n",
            "Downloading krippendorff-0.8.2-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: krippendorff\n",
            "Successfully installed krippendorff-0.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "import krippendorff\n",
        "import numpy as np\n",
        "import glob\n",
        "import os"
      ],
      "metadata": {
        "id": "E7MBP1c7jZGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_disc_author(filename):\n",
        "\n",
        "    base = os.path.splitext(filename)[0]         # remove .xlsx\n",
        "    base = base.replace(\"_merged\", \"\")           # remove merged\n",
        "    parts = base.split(\"_\")\n",
        "\n",
        "    discipline = parts[0]                        # first token\n",
        "    author = \"_\".join(parts[1:])                 # everything after\n",
        "\n",
        "    return discipline, author\n"
      ],
      "metadata": {
        "id": "ljfp3vTdjauM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def calculate_krippendorffs_alpha(df_list, columns):\n",
        "    \"\"\"\n",
        "    Krippendorff's alpha:\n",
        "    - Evaluative: computed on all rows\n",
        "    - Other columns: computed ONLY where Evaluative == 1 for ALL annotators\n",
        "    \"\"\"\n",
        "    alphas = {}\n",
        "\n",
        "    for col in columns:\n",
        "        data = []\n",
        "\n",
        "        # mask logic\n",
        "        if col == \"Evaluative\":\n",
        "            mask = np.ones(len(df_list[0]), dtype=bool)\n",
        "        else:\n",
        "            # ONLY rows where all annotators marked Evaluative == 1\n",
        "            mask = np.logical_and.reduce(\n",
        "                [df[\"Evaluative\"] == 1 for df in df_list]\n",
        "            )\n",
        "\n",
        "        for df in df_list:\n",
        "            col_data = df.loc[mask, col].replace(-1, np.nan).to_numpy()\n",
        "            data.append(col_data)\n",
        "\n",
        "        data = np.array(data)\n",
        "\n",
        "        # skip if no usable data\n",
        "        if data.shape[1] == 0:\n",
        "            alphas[col] = np.nan\n",
        "            continue\n",
        "\n",
        "        # skip if only one unique value\n",
        "        unique_vals = np.unique(data[~np.isnan(data)])\n",
        "        if len(unique_vals) <= 1:\n",
        "            alphas[col] = np.nan\n",
        "            continue\n",
        "\n",
        "        alphas[col] = krippendorff.alpha(\n",
        "            reliability_data=data,\n",
        "            level_of_measurement=\"nominal\"\n",
        "        )\n",
        "\n",
        "    return alphas\n"
      ],
      "metadata": {
        "id": "CYmbjKUgjdF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FOR EACH FILE\n",
        "results = []\n",
        "\n",
        "common_dfs = []\n",
        "\n",
        "gold_file = \"/content/Gold_standard_Mirela.xlsx\"\n",
        "df_gold = pd.read_excel(gold_file)\n",
        "\n",
        "# Normalize gold file\n",
        "df_gold = df_gold.fillna(0)\n",
        "\n",
        "\n",
        "df_gold = df_gold.fillna(0)\n",
        "#df_gold2 = df_gold2.drop(index=5)\n",
        "\n",
        "#Just to be sure of int values\n",
        "df_gold['Evaluative'] = df_gold['Evaluative'].astype(int)\n",
        "df_gold['Affect'] = df_gold['Affect'].astype(int)\n",
        "df_gold['Judgement'] = df_gold['Judgement'].astype(int)\n",
        "df_gold['Appreciation'] = df_gold['Appreciation'].astype(int)\n",
        "df_gold['Ambiguous'] = df_gold['Ambiguous'].astype(int)\n",
        "#df_gold['Uncertain'] = df_gold['Uncertain'].astype(int)\n",
        "for col in ['Evaluative','Affect','Judgement','Appreciation','Ambiguous']:\n",
        "    df_gold[col] = df_gold[col].astype(int)\n",
        "\n",
        "# Path where student files live\n",
        "student_files = glob.glob(\"/content/output/output/*.xlsx\")\n",
        "print(student_files)\n",
        "\n",
        "\n",
        "for file in student_files:\n",
        "    df2 = pd.read_excel(file)\n",
        "\n",
        "    # Clean student file\n",
        "    # Identify any column whose name equals 'uncertain' ignoring case sometimes it was 'Uncertain'\n",
        "    uncertain_cols = [c for c in df2.columns if c.lower() == 'uncertain']\n",
        "\n",
        "    # Remove rows where uncertain == 1 cause that result is not useful for us!!\n",
        "    for col in uncertain_cols:\n",
        "        df2 = df2[df2[col] != 1]\n",
        "\n",
        "    df2 = df2.drop(['uncertain','Notes'], axis=1, errors='ignore').fillna(0)\n",
        "    for col in ['Evaluative','Affect','Judgement','Appreciation','Ambiguous']:\n",
        "        df2[col] = df2[col].astype(int)\n",
        "\n",
        "    df2 = df2.fillna(0)\n",
        "\n",
        "    df2['Evaluative'] = df2['Evaluative'].astype(int)\n",
        "    df2['Affect'] = df2['Affect'].astype(int)\n",
        "    df2['Judgement'] = df2['Judgement'].astype(int)\n",
        "    df2['Appreciation'] = df2['Appreciation'].astype(int)\n",
        "    df2['Ambiguous'] = df2['Ambiguous'].astype(int)\n",
        "    #df2['Uncertain'] = df2['Uncertain'].astype(int)\n",
        "\n",
        "    # Align based on Text_ID + Sentence_ID\n",
        "    common_pairs = df_gold.merge(\n",
        "        df2[['Text_ID','Sentence_ID']],\n",
        "        on=['Text_ID','Sentence_ID'],\n",
        "        how='inner'\n",
        "    )[['Text_ID','Sentence_ID']]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    df1_aligned = df_gold.merge(common_pairs, on=['Text_ID','Sentence_ID'], how='inner')\n",
        "    df2_aligned = df2.merge(common_pairs, on=['Text_ID','Sentence_ID'], how='inner')\n",
        "\n",
        "    # SORTING IS VERY IMPORTANT OTHERWISE IT JUST CHECKS ON WHATEVER ORDER IT OCCURS\n",
        "    df1_aligned = df1_aligned.sort_values(['Text_ID','Sentence_ID']).reset_index(drop=True)\n",
        "    df2_aligned = df2_aligned.sort_values(['Text_ID','Sentence_ID']).reset_index(drop=True)\n",
        "\n",
        "    # --- Compute Cohen's Kappa ---\n",
        "    kappa = cohen_kappa_score(df1_aligned[\"Evaluative\"], df2_aligned[\"Evaluative\"])\n",
        "\n",
        "    # --- Compute Krippendorff's Alpha ---\n",
        "    cols_to_check = ['Evaluative','Affect','Judgement','Appreciation','Ambiguous']\n",
        "    alphas = calculate_krippendorffs_alpha([df1_aligned, df2_aligned], cols_to_check)\n",
        "    filename = os.path.basename(file)\n",
        "    discipline, author = extract_disc_author(filename)\n",
        "\n",
        "    results.append({\n",
        "        \"discipline\": discipline,\n",
        "        \"author\": author,\n",
        "        \"cohen_kappa\": kappa,\n",
        "        **alphas\n",
        "    })\n",
        "\n",
        "\n",
        "    # ---------------------------------------------\n",
        "    # Build common gold–student dataframe\n",
        "    # ---------------------------------------------\n",
        "    common_df = df1_aligned.merge(\n",
        "    df2_aligned,\n",
        "    on=['Text_ID', 'Sentence_ID'],\n",
        "    how='inner',\n",
        "    suffixes=('_gold', '_student')\n",
        "    )\n",
        "\n",
        "    # Add metadata columns\n",
        "    common_df.insert(0, 'author', author)\n",
        "    common_df.insert(0, 'discipline', discipline)\n",
        "\n",
        "    common_dfs.append(common_df)\n",
        "\n",
        "\n",
        "# Convert to DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_excel(\"annotation_agreement_results.xlsx\", index=False)\n",
        "print(results_df)\n",
        "\n",
        "final_common_df = pd.concat(common_dfs, ignore_index=True)\n",
        "\n",
        "assert not final_common_df.duplicated(\n",
        "    ['author', 'Text_ID', 'Sentence_ID']\n",
        ").any()\n",
        "\n",
        "final_common_df.to_excel(\n",
        "    \"common_gold_student_annotations.xlsx\",\n",
        "    index=False\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qbaN3lVIro9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Author level\n",
        "\n",
        "LABEL_COLS = [\n",
        "    'Evaluative',\n",
        "    'Affect',\n",
        "    'Judgement',\n",
        "    'Appreciation',\n",
        "    'Ambiguous'\n",
        "]\n",
        "gold_label_cols = [c for c in final_common_df.columns if c.endswith('_gold')]\n",
        "student_label_cols = [c for c in final_common_df.columns if c.endswith('_student')]\n",
        "author_results = []\n",
        "\n",
        "for author, df_author in final_common_df.groupby('author'):\n",
        "\n",
        "    # ---------------------------------------------\n",
        "    # Cohen’s Kappa (Evaluative)\n",
        "    # ---------------------------------------------\n",
        "\n",
        "    kappa = cohen_kappa_score(\n",
        "        df_author['Evaluative_gold'],\n",
        "        df_author['Evaluative_student']\n",
        "    )\n",
        "\n",
        "    # ---------------------------------------------\n",
        "    # Krippendorff’s Alpha\n",
        "    # ---------------------------------------------\n",
        "\n",
        "    df_gold_author = df_author[[c for c in gold_label_cols]].copy()\n",
        "    df_student_author = df_author[[c for c in student_label_cols]].copy()\n",
        "\n",
        "    # Remove suffixes so column names match\n",
        "    df_gold_author.columns = [c.replace('_gold', '') for c in df_gold_author.columns]\n",
        "    df_student_author.columns = [c.replace('_student', '') for c in df_student_author.columns]\n",
        "\n",
        "    alphas = calculate_krippendorffs_alpha(\n",
        "        [df_gold_author, df_student_author],\n",
        "        LABEL_COLS\n",
        "    )\n",
        "\n",
        "    author_results.append({\n",
        "        'author': author,\n",
        "        'disciplines_merged': sorted(df_author['discipline'].unique().tolist()),\n",
        "        'n_sentences': len(df_author),\n",
        "        'cohen_kappa': kappa,\n",
        "        **alphas\n",
        "    })\n"
      ],
      "metadata": {
        "id": "qsS3z49Stnyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "author_results_df = pd.DataFrame(author_results)\n",
        "author_results_df.to_excel(\n",
        "    \"annotation_agreement_results_by_author.xlsx\",\n",
        "    index=False\n",
        ")\n",
        "\n",
        "print(author_results_df)\n"
      ],
      "metadata": {
        "id": "Tq5Shq7gtPQj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}